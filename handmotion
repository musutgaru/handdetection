import os
import numpy as np

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import (
    Masking, LSTM, Dense, Dropout, BatchNormalization
)
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ProgbarLogger
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.optimizers.schedules import ExponentialDecay

# (live_quiz_session에서만 사용할 경우)
from tensorflow.keras.applications import VGG16

param = {
    'batch_size':           32,
    'time_steps':           60,    # 이미 60프레임으로 저장된 데이터를 그대로 씁니다
    'height':               224,
    'width':                224,
    'channels':             3,
    'lstm_dropout':         0.2,
    'lstm_recurrent_dropout': 0.2,
    'model_dense_units1':   64,    # → 256에서 64로 축소
    'model_dropout1':       0.3,
    'learning_rate':        1e-3,
    'patience':             5,
    'model_dir':            'best_sign_lang_model.h5',
    'epoch':                500,
    'rnd_seed':             42
}


# ─── Cell 3 (손 2개로 자른 뒤 패딩) ───────────────────────────────────────
import os, shutil, cv2, numpy as np, pandas as pd, mediapipe as mp
from tensorflow.keras.utils import to_categorical

def extract_preprocess_and_save(
    video_dir, frames_dir, excel_path,
    fps=param['time_steps'], size=(param['height'], param['width'])
):
    # 0) 이어쓰기 묻기
    npy_x = os.path.join(frames_dir, 'X_keypoints.npy')
    npy_y = os.path.join(frames_dir, 'y_onehot.npy')
    resume = os.path.exists(npy_x) and input(f"'{frames_dir}' 이어쓰기? ([y]/n): ").strip().lower() in ('','y','yes')

    # 1) 초기화 or 유지
    if not resume:
        shutil.rmtree(frames_dir, ignore_errors=True)
        os.makedirs(frames_dir, exist_ok=True)
        for f in (npy_x, npy_y):
            try: os.remove(f)
            except: pass
    else:
        os.makedirs(frames_dir, exist_ok=True)

    # 2) 메타 & 클래스 맵
    meta = pd.read_excel(excel_path, engine='openpyxl')
    meta['한국어'] = meta['한국어'].astype(str)
    meta['파일명'] = meta['파일명'].astype(str)
    classes = sorted(meta['한국어'].unique())
    c2i     = {c:i for i,c in enumerate(classes)}
    num_cls = len(classes)

    # 3) 누적 NPY 불러오기 or 빈 배열 생성
    if resume and os.path.exists(npy_x):
        X_all = np.load(npy_x)   # (N_prev, fps, 92)
        y_all = np.load(npy_y)
    else:
        X_all = np.zeros((0, fps, 92), dtype=np.float32)
        y_all = np.zeros((0, num_cls), dtype=np.float32)

    # 4) MediaPipe 세팅
    mp_pose  = mp.solutions.pose.Pose(min_detection_confidence=0.5,
                                      min_tracking_confidence=0.5)
    mp_hands = mp.solutions.hands.Hands(min_detection_confidence=0.5,
                                        min_tracking_confidence=0.5,
                                        max_num_hands=2)

    # 5) 비디오별 처리
    for _, row in meta.iterrows():
        name, _ = os.path.splitext(row['파일명'])
        lbl_idx = c2i[row['한국어']]

        # (5.1) 파일 찾기
        vid = None
        for ext in ('.MTS','.MOV','.MP4','.AVI'):
            candidate = os.path.join(video_dir, name+ext)
            if os.path.isfile(candidate):
                vid = candidate
                break
        if vid is None:
            print("경로 없음:", name)
            continue

        # (5.2) 프레임 읽고 균일 샘플링 인덱스
        cap    = cv2.VideoCapture(vid)
        frames = []
        while True:
            ret, frm = cap.read()
            if not ret: break
            frames.append(frm)
        cap.release()
        M = len(frames)
        if M == 0:
            print(f"[{row['한국어']}/{name}] 프레임 없음, 스킵")
            continue
        idxs = np.linspace(0, M-1, fps, dtype=int)

        seq = []
        for i in idxs:
            frame = cv2.resize(frames[i], size)
            rgb   = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            p_res = mp_pose.process(rgb)
            h_res = mp_hands.process(rgb)

            # **매 프레임마다 coords 초기화**
            coords = []

            # (1) 어깨·팔꿈치
            if p_res.pose_landmarks:
                for j in (11,13,12,14):
                    lm = p_res.pose_landmarks.landmark[j]
                    coords += [lm.x, lm.y]
            else:
                coords += [0.0]*8

            # (2) 손 랜드마크 → 최대 2손만 취함
            hands = (h_res.multi_hand_landmarks or [])[:2]
            for hand_lm in hands:
                for lm in hand_lm.landmark:
                    coords += [lm.x, lm.y]

            # (3) 패딩: 0손→84, 1손→42, 2손→0
            if len(hands) == 0:
                coords += [0.0]*84
            elif len(hands) == 1:
                coords += [0.0]*42
            # len(hands)==2면 그대로

            assert len(coords) == 92, f"PTS 길이 오류: {len(coords)}"
            seq.append(coords)

        per_seq = np.array(seq, dtype=np.float32)        # (fps,92)
        per_lbl = to_categorical(lbl_idx, num_cls)       # (num_cls,)

        print(f"[{row['한국어']}/{name}] 완료: {len(seq)}/{fps} 샘플링")

        # (5.3) per-video 백업
        np.savez(os.path.join(frames_dir, f"{name}.npz"),
                 pts=per_seq, label=per_lbl)

        # (5.4) 누적 NPY에 붙이기 & 저장
        X_all = np.concatenate([X_all, per_seq[np.newaxis,...]], axis=0)
        y_all = np.concatenate([y_all, per_lbl[np.newaxis,...]], axis=0)
        np.save(npy_x, X_all)
        np.save(npy_y, y_all)

    # 6) 클래스 리스트 저장
    np.save(os.path.join(frames_dir,'class_list.npy'),
            np.array(classes, dtype=object))

frames_root = os.path.expanduser('~/Desktop/jeongeun/DL/keypoints')
class_list = np.load(os.path.join(frames_root, 'class_list.npy'), allow_pickle=True)
param['num_classes'] = len(class_list)

def load_VGG16():
    base_model = VGG16(
        weights='imagenet',
        include_top=False,
        input_shape=(param['height'], param['width'], param['channels'])
    )
    base_model.trainable = True
    return base_model

import tensorflow as tf

def build_tfdata_dataset(
    frames_root: str,
    excel_path:  str,
    param:      dict
) -> tf.data.Dataset:
    """
    메타 엑셀을 읽어 (경로,레이블) 쌍을 만든 뒤,
    tf.data.Dataset.map + tf.numpy_function 으로
    프레임 시퀀스를 배치 단위로 스트리밍 로드합니다.
    """
    # 1) 엑셀 → meta DataFrame
    meta = pd.read_excel(excel_path, engine='openpyxl')
    meta['한국어'] = meta['한국어'].astype(str)
    meta['파일명'] = meta['파일명'].astype(str)

    classes   = sorted(meta['한국어'].unique())
    class2idx = {c:i for i,c in enumerate(classes)}
    num_classes = len(classes)

    # 2) (bytes-path, label_idx) 리스트 준비
    pairs = []
    for _, row in meta.iterrows():
        korean = row['한국어']
        prefix = row['파일명']
        # 구분자 /// 로 묶어서 한 문자열로 전달
        pairs.append((f"{korean}///{prefix}".encode('utf-8'),
                      class2idx[korean]))
    paths, labels = zip(*pairs)
    paths  = np.array(paths)
    labels = np.array(labels, dtype=np.int32)

    # 3) Python-side 로더
    def _py_load(path_bytes, label_idx):
        s = path_bytes.decode('utf-8')
        korean, prefix = s.split('///')
        folder = os.path.join(frames_root, korean, prefix)
        seq = []
        for t in range(param['time_steps']):
            img_path = os.path.join(folder, f"{prefix}_f{t:03d}.jpg")
            if os.path.exists(img_path):
                im = cv2.imread(img_path)
                im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
            else:
                im = seq[-1] if seq else np.zeros(
                    (param['height'], param['width'], 3), np.uint8)
            seq.append(im)
        arr = np.stack(seq, axis=0)  # (T, H, W, C)
        # return flattened + one-hot label
        return arr.astype(np.uint8).flatten(), tf.keras.utils.to_categorical(
            label_idx, num_classes=num_classes).astype(np.float32)

    # 4) tf.data 파이프라인
    ds = tf.data.Dataset.from_tensor_slices((paths, labels))
    ds = ds.map(
        lambda p, l: tf.numpy_function(
            _py_load, [p, l],
            [tf.uint8, tf.float32]
        ),
        num_parallel_calls=tf.data.AUTOTUNE
    )
    # 5) reshape, batch, shuffle, prefetch
    ds = ds.map(
        lambda seq_flat, lab: (
            tf.reshape(
                seq_flat,
                [param['time_steps'], param['height'], param['width'], param['channels']]
            ),
            lab
        ),
        num_parallel_calls=tf.data.AUTOTUNE
    )
    ds = ds.shuffle(1000) \
           .batch(param['batch_size']) \
           .prefetch(tf.data.AUTOTUNE)
    return ds, classes


def sign_lang_model():
    # ExponentialDecay 스케줄러
    lr_schedule = ExponentialDecay(
        initial_learning_rate=param['learning_rate'],
        decay_steps=10000,
        decay_rate=0.96,
        staircase=True
    )

    model = Sequential([
        # (mask_value=0 로 패딩된 프레임 무시)
        Masking(mask_value=0.0, input_shape=(param['time_steps'], 92)),

        # LSTM 블록: 유닛 64, 활성화 relu
        LSTM(
            64,
            activation='relu',
            dropout=param['lstm_dropout'],
            recurrent_dropout=param['lstm_recurrent_dropout']
        ),

        # 배치 정규화 → 안정적 수렴
        BatchNormalization(),

        # 은닉층: 64 유닛
        Dense(param['model_dense_units1'], activation='relu'),
        Dropout(param['model_dropout1']),

        # 최종 출력: 클래스 수만큼
        Dense(param['num_classes'], activation='softmax')
    ])

    model.compile(
        optimizer=SGD(
            learning_rate=lr_schedule,
            momentum=0.9,
            nesterov=True
        ),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    return model


def train_model(model, dataset_train, dataset_val):
    es = EarlyStopping(
        monitor='val_loss',
        patience=param['patience'],
        restore_best_weights=True,
        verbose=1
    )
    callbacks = [
        es,
        ModelCheckpoint(
            filepath=param['model_dir'],
            monitor='val_accuracy',
            save_best_only=True,
            verbose=1
        ),
        ProgbarLogger(count_mode='steps')
    ]

    history = model.fit(
        dataset_train,
        validation_data=dataset_val,
        epochs=param['epoch'],
        batch_size=param['batch_size'],
        callbacks=callbacks,
        shuffle=True,
        verbose=1
    )
    print("Stopped at epoch", es.stopped_epoch + 1)
    return history, es.stopped_epoch

import matplotlib.pyplot as plt

def plot_loss_acc(history, upto_epoch=None):
    fig, (axL, axA) = plt.subplots(1, 2, figsize=(12,4))

    ep = history.history['loss']
    val_ep = history.history['val_loss']
    axL.plot(ep,     label='train loss')
    axL.plot(val_ep, label='val   loss')
    axL.set_title('Loss')
    axL.legend()

    acc = history.history['accuracy']
    vacc = history.history['val_accuracy']
    axA.plot(acc,  label='train acc')
    axA.plot(vacc, label='val   acc')
    axA.set_title('Accuracy')
    axA.legend()

    if upto_epoch is not None:
        axL.axvline(upto_epoch-1, color='gray', linestyle='--')
        axA.axvline(upto_epoch-1, color='gray', linestyle='--')

    plt.show()

from sklearn.model_selection import train_test_split
import tensorflow as tf

# 1) NPY 불러오기
X = np.load(os.path.join(frames_root, 'X_keypoints.npy'))   # (N,60,92)
y = np.load(os.path.join(frames_root, 'y_onehot.npy'))      # (N,419)

# 2) train/val 분할 (stratify)
y_idx = y.argmax(axis=1)
X_train, X_val, y_train, y_val = train_test_split(
    X, y,
    test_size=0.2,
    stratify=y_idx,
    random_state=param['rnd_seed']
)
print("Train:", X_train.shape, y_train.shape)
print("Valid:", X_val.shape,   y_val.shape)

# 3) 래핑
train_ds = (
    tf.data.Dataset.from_tensor_slices((X_train, y_train))
    .shuffle(buffer_size=len(X_train))
    .batch(param['batch_size'], drop_remainder=True)
    .prefetch(tf.data.AUTOTUNE)
)
val_ds = (
    tf.data.Dataset.from_tensor_slices((X_val, y_val))
    .batch(param['batch_size'], drop_remainder=False)
    .prefetch(tf.data.AUTOTUNE)
)

# 4) 모델 생성 & 학습
model = sign_lang_model()
history, stopped = train_model(model, train_ds, val_ds)

# 5) 그래프
plot_loss_acc(history, upto_epoch=stopped+1)

